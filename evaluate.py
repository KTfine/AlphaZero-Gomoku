"""
è¯„ä¼°å’Œå¯¹æˆ˜å·¥å…·
"""

import torch
import numpy as np
from gomoku_game import GomokuGame
from network import AlphaZeroNet
from mcts import MCTS, PureMCTS
from config import Config


class Evaluator:
    """æ¨¡åž‹è¯„ä¼°å™¨"""
    
    def __init__(self, model1, model2=None, num_simulations=100):
        """
        Args:
            model1: ç¬¬ä¸€ä¸ªæ¨¡åž‹ï¼ˆè¢«è¯„ä¼°çš„æ¨¡åž‹ï¼‰
            model2: ç¬¬äºŒä¸ªæ¨¡åž‹ï¼ˆåŸºå‡†æ¨¡åž‹ï¼‰ï¼Œå¦‚æžœä¸ºNoneåˆ™ä½¿ç”¨çº¯MCTS
            num_simulations: MCTSæ¨¡æ‹Ÿæ¬¡æ•°
        """
        self.model1 = model1
        self.model2 = model2
        self.num_simulations = num_simulations
        
        self.agent1 = MCTS(model1, num_simulations=num_simulations, temperature=0)
        
        if model2 is not None:
            self.agent2 = MCTS(model2, num_simulations=num_simulations, temperature=0)
        else:
            self.agent2 = PureMCTS(num_simulations=num_simulations)
    
    def play_game(self, agent1_first=True, verbose=False):
        """
        ä¸¤ä¸ªAIå¯¹å¼ˆä¸€å±€
        Args:
            agent1_first: agent1æ˜¯å¦å…ˆæ‰‹
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        Returns:
            winner: 1(agent1èƒœ), -1(agent2èƒœ), 0(å¹³å±€)
        """
        game = GomokuGame(Config.BOARD_SIZE)
        
        # ç¡®å®šå“ªä¸ªagentå…ˆæ‰‹
        if agent1_first:
            agents = {1: self.agent1, -1: self.agent2}
        else:
            agents = {1: self.agent2, -1: self.agent1}
        
        step = 0
        while not game.is_game_over():
            current_agent = agents[game.current_player]
            move = current_agent.get_action(game)
            
            if move is None:
                break
            
            game.make_move(move[0], move[1])
            step += 1
            
            if verbose and step % 20 == 0:
                print(f"æ­¥æ•°: {step}")
        
        winner = game.get_winner()
        
        # è½¬æ¢ä¸ºagent1çš„è§†è§’
        if agent1_first:
            return winner
        else:
            return -winner if winner != 0 else 0
    
    def evaluate(self, num_games=20, verbose=True):
        """
        è¯„ä¼°æ¨¡åž‹
        Args:
            num_games: å¯¹å¼ˆå±€æ•°ï¼ˆagent1å…ˆæ‰‹å’ŒåŽæ‰‹å„ä¸€åŠï¼‰
        Returns:
            win_rate: agent1çš„èƒœçŽ‡
        """
        wins = 0
        losses = 0
        draws = 0
        
        # ä¸€åŠå…ˆæ‰‹ï¼Œä¸€åŠåŽæ‰‹
        for i in range(num_games):
            agent1_first = (i % 2 == 0)
            
            if verbose:
                print(f"å¯¹å±€ {i+1}/{num_games}: ", end='')
                print(f"Agent1 {'å…ˆæ‰‹' if agent1_first else 'åŽæ‰‹'} ... ", end='', flush=True)
            
            result = self.play_game(agent1_first=agent1_first, verbose=False)
            
            if result == 1:
                wins += 1
                if verbose:
                    print("èƒœ")
            elif result == -1:
                losses += 1
                if verbose:
                    print("è´Ÿ")
            else:
                draws += 1
                if verbose:
                    print("å¹³")
        
        win_rate = wins / num_games
        
        if verbose:
            print(f"\nè¯„ä¼°ç»“æžœ:")
            print(f"  èƒœ: {wins}/{num_games} ({wins/num_games*100:.1f}%)")
            print(f"  è´Ÿ: {losses}/{num_games} ({losses/num_games*100:.1f}%)")
            print(f"  å¹³: {draws}/{num_games} ({draws/num_games*100:.1f}%)")
            print(f"  èƒœçŽ‡: {win_rate*100:.1f}%")
        
        return win_rate


def compare_models(model_path1, model_path2=None, num_games=20, num_simulations=100):
    """
    æ¯”è¾ƒä¸¤ä¸ªæ¨¡åž‹çš„å¼ºåº¦
    Args:
        model_path1: ç¬¬ä¸€ä¸ªæ¨¡åž‹è·¯å¾„
        model_path2: ç¬¬äºŒä¸ªæ¨¡åž‹è·¯å¾„ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨çº¯MCTSï¼‰
        num_games: å¯¹å¼ˆå±€æ•°
        num_simulations: MCTSæ¨¡æ‹Ÿæ¬¡æ•°
    """
    print("åŠ è½½æ¨¡åž‹...")
    
    # åŠ è½½æ¨¡åž‹1
    model1 = AlphaZeroNet(board_size=Config.BOARD_SIZE,
                         num_channels=Config.NUM_CHANNELS,
                         num_res_blocks=Config.NUM_RES_BLOCKS)
    checkpoint1 = torch.load(model_path1, map_location='cpu', weights_only=False)
    model1.load_state_dict(checkpoint1['model_state_dict'])
    model1.eval()
    print(f"æ¨¡åž‹1å·²åŠ è½½: {model_path1}")
    
    # åŠ è½½æ¨¡åž‹2
    model2 = None
    if model_path2 is not None:
        model2 = AlphaZeroNet(board_size=Config.BOARD_SIZE,
                             num_channels=Config.NUM_CHANNELS,
                             num_res_blocks=Config.NUM_RES_BLOCKS)
        checkpoint2 = torch.load(model_path2, map_location='cpu', weights_only=False)
        model2.load_state_dict(checkpoint2['model_state_dict'])
        model2.eval()
        print(f"æ¨¡åž‹2å·²åŠ è½½: {model_path2}")
    else:
        print("æ¨¡åž‹2: çº¯MCTS")
    
    # è¯„ä¼°
    print(f"\nå¼€å§‹è¯„ä¼°ï¼ˆ{num_games}å±€å¯¹å¼ˆï¼‰...")
    evaluator = Evaluator(model1, model2, num_simulations=num_simulations)
    win_rate = evaluator.evaluate(num_games=num_games, verbose=True)
    
    return win_rate


def play_against_human(model_path, human_first=True, num_simulations=100):
    """
    äººæœºå¯¹æˆ˜ï¼ˆå‘½ä»¤è¡Œç‰ˆæœ¬ï¼‰
    Args:
        model_path: æ¨¡åž‹è·¯å¾„
        human_first: äººç±»æ˜¯å¦å…ˆæ‰‹
        num_simulations: MCTSæ¨¡æ‹Ÿæ¬¡æ•°
    """
    print("åŠ è½½æ¨¡åž‹...")
    model = AlphaZeroNet(board_size=Config.BOARD_SIZE,
                        num_channels=Config.NUM_CHANNELS,
                        num_res_blocks=Config.NUM_RES_BLOCKS)
    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    print("æ¨¡åž‹åŠ è½½æˆåŠŸï¼\n")
    
    ai = MCTS(model, num_simulations=num_simulations, temperature=0)
    game = GomokuGame(Config.BOARD_SIZE)
    
    human_player = 1 if human_first else -1
    
    print("=" * 50)
    print("AlphaZero äº”å­æ£‹ - äººæœºå¯¹æˆ˜")
    print("=" * 50)
    print(f"ä½ æ‰§: {'é»‘æ£‹ (å…ˆæ‰‹)' if human_first else 'ç™½æ£‹ (åŽæ‰‹)'}")
    print("è¾“å…¥æ ¼å¼: è¡Œ åˆ— (ä¾‹å¦‚: 7 7)")
    print("è¾“å…¥ 'q' é€€å‡º")
    print("=" * 50)
    
    game.display()
    
    while not game.is_game_over():
        if game.current_player == human_player:
            # äººç±»å›žåˆ
            while True:
                try:
                    user_input = input(f"\nä½ çš„å›žåˆ ({'â—' if human_player == 1 else 'â—‹'}): ").strip()
                    
                    if user_input.lower() == 'q':
                        print("æ¸¸æˆç»“æŸ")
                        return
                    
                    row, col = map(int, user_input.split())
                    
                    if game.make_move(row, col):
                        break
                    else:
                        print("æ— æ•ˆè½å­ï¼Œè¯·é‡è¯•")
                except (ValueError, IndexError):
                    print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥: è¡Œ åˆ—")
        else:
            # AIå›žåˆ
            print(f"\nAIæ€è€ƒä¸­ ({'â—' if game.current_player == 1 else 'â—‹'})...")
            move = ai.get_action(game)
            game.make_move(move[0], move[1])
            print(f"AIè½å­: {move[0]} {move[1]}")
        
        game.display()
    
    # æ¸¸æˆç»“æŸ
    print("\n" + "=" * 50)
    winner = game.get_winner()
    if winner == human_player:
        print("ä½ èµ¢äº†ï¼ðŸŽ‰")
    elif winner == -human_player:
        print("AIèŽ·èƒœï¼")
    else:
        print("å¹³å±€ï¼")
    print("=" * 50)


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
        
        if len(sys.argv) > 2:
            # æ¯”è¾ƒä¸¤ä¸ªæ¨¡åž‹
            model_path2 = sys.argv[2]
            compare_models(model_path, model_path2, num_games=20)
        else:
            # äººæœºå¯¹æˆ˜
            play_against_human(model_path, human_first=True)
    else:
        print("ç”¨æ³•:")
        print("  äººæœºå¯¹æˆ˜: python evaluate.py <æ¨¡åž‹è·¯å¾„>")
        print("  æ¨¡åž‹å¯¹æ¯”: python evaluate.py <æ¨¡åž‹1è·¯å¾„> <æ¨¡åž‹2è·¯å¾„>")
